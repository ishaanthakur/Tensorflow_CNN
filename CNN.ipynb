{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 4250 Final Kaggle Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import scipy\n",
    "from scipy import ndimage, signal, stats\n",
    "from scipy.optimize import fmin\n",
    "from scipy.ndimage import rotate\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cmath\n",
    "import cv2\n",
    "from cv2 import warpAffine\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import tabulate\n",
    "import random\n",
    "import scipy\n",
    "import skimage\n",
    "from scipy import ndimage\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from skimage.transform import warp, AffineTransform\n",
    "from IPython.display import HTML, display\n",
    "from skimage import transform, draw, filters\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img , training_sgm, validation_img , validation_sgm, testing_img = [], [], [], [], []\n",
    "\n",
    "loc_validation_img, loc_validation_sgm = ['./4250-Data/Validation/IBSR_'+ i + '/images/analyze/IBSR_' + i +'_ana.img' for i in ['07', '15']],['./4250-Data/Validation/IBSR_'+ i + '/segmentation/analyze/IBSR_' + i +'_seg_ana.img' for i in ['07', '15']]\n",
    "\n",
    "loc_training_img, loc_training_sgm  = ['./4250-Data/Training/IBSR_0'+ str(i) + '/images/analyze/IBSR_0' + str(i) +'_ana.img' for i in range(1,7)],['./4250-Data/Training/IBSR_0'+ str(i) + '/segmentation/analyze/IBSR_0' + str(i) +'_seg_ana.img' for i in range(1,7)]\n",
    "\n",
    "loc_testing_img , temp = [], ['08','09','10','11','12','13','14','16','17']\n",
    "\n",
    "for i in temp:\n",
    "    loc_testing_img.append('./4250-Data/Testing/IBSR_'+ i + '/images/analyze/IBSR_' + i + '_ana.img')\n",
    "    \n",
    "def Sliced(img): ## input is of type nibabel image \n",
    "    img_data = img.get_fdata()\n",
    "    return img_data[:, :, int(len(img_data[0,0])/2) ] ## removed the rotation\n",
    "\n",
    "for i in range(len(loc_validation_img)):\n",
    "    validation_img.append(Sliced(nib.load(loc_validation_img[i])))\n",
    "    validation_sgm.append(Sliced(nib.load(loc_validation_sgm[i])))\n",
    "\n",
    "for i in range(len(loc_training_img)):\n",
    "    training_img.append(Sliced(nib.load(loc_training_img[i])))\n",
    "    training_sgm.append(Sliced(nib.load(loc_training_sgm[i])))\n",
    "\n",
    "for i in loc_testing_img:\n",
    "    testing_img.append(Sliced(nib.load(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using SkImage Affine Transfrm implementation for the geometric transformation\n",
    "\n",
    "def Trnsfrm(moving_img, glbl_sc_x, glbl_sc_y, theta, t_x, t_y, sh, grid_size_out):\n",
    "    \n",
    "    dim1,dim2, dim3, dim4 = len(moving_img), len(moving_img[0]), grid_size_out[0], grid_size_out[1] \n",
    "    \n",
    "    trns_y, trns_x = (np.array((dim3, dim4))-1) / 2.\n",
    "    \n",
    "    frnt, bck= transform.SimilarityTransform(translation=[-trns_x, -trns_y]), transform.SimilarityTransform(translation=[trns_x, trns_y])    \n",
    "    \n",
    "    Aff_Trnform = AffineTransform(scale=(glbl_sc_x, glbl_sc_y), rotation=np.deg2rad(theta), shear=sh, translation=(t_x, t_y))\n",
    "    \n",
    "    ret = warp( moving_img , ( frnt + (Aff_Trnform + bck )).inverse, order=1, clip=False, preserve_range=True, mode='symmetric')\n",
    "    \n",
    "    return ret\n",
    "\n",
    "\n",
    "## Switched to Structural Similarity as opposed to MSE used in Milestone 2\n",
    "\n",
    "def Loss(Trns_par, fix_img, mv_img):    \n",
    "    \n",
    "    geom = Trnsfrm(mv_img, *Trns_par, fix_img.shape) \n",
    "\n",
    "    return(-1* skimage.measure.compare_ssim(skimage.color.rgb2gray(geom), skimage.color.rgb2gray(fix_img)))\n",
    "    \n",
    "\n",
    "## Using Powell Optimizer for Minimizing\n",
    "\n",
    "def Optmzer(fix_img, mv_img): ## Try different optimizations \n",
    " \n",
    "    norm_fix_img, norm_mv_img  = cv2.normalize(fix_img, 0, 255, cv2.NORM_MINMAX) , cv2.normalize(mv_img, 0, 255, cv2.NORM_MINMAX)   \n",
    "    opt_par = scipy.optimize.minimize(Loss, (1,1,0,0,0,0), args = (norm_fix_img,norm_mv_img), method = 'Powell')\n",
    "    transf_img = Trnsfrm(mv_img, *opt_par.x, fix_img.shape)\n",
    "    \n",
    "    return  transf_img, opt_par.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n"
     ]
    }
   ],
   "source": [
    "opt_par, opt_par_val = [Optmzer(i, j)[1] for i in testing_img for j in training_img],[Optmzer(i, j)[1] for i in testing_img for j in validation_img]\n",
    "\n",
    "sgm_img = np.zeros((9,8,256,256,1)) ## array for storing 6 training + 2 validation segments for\n",
    "                                    ## each of the testing image\n",
    "\n",
    "## Mapping each of the 6 training segments to each of the 8 testing images\n",
    "for i in range(6): \n",
    "    sgm_img[0, i] = Trnsfrm(training_sgm[i], *opt_par[i], testing_img[0].shape)\n",
    "    sgm_img[1, i] = Trnsfrm(training_sgm[i], *opt_par[6+i], testing_img[1].shape)\n",
    "    sgm_img[2, i] = Trnsfrm(training_sgm[i], *opt_par[12+i], testing_img[2].shape)\n",
    "    sgm_img[3, i] = Trnsfrm(training_sgm[i], *opt_par[18+i], testing_img[3].shape)\n",
    "    sgm_img[4, i] = Trnsfrm(training_sgm[i], *opt_par[24+i], testing_img[4].shape)\n",
    "    sgm_img[5, i] = Trnsfrm(training_sgm[i], *opt_par[30+i], testing_img[5].shape)\n",
    "    sgm_img[6, i] = Trnsfrm(training_sgm[i], *opt_par[36+i], testing_img[6].shape)\n",
    "    sgm_img[7, i] = Trnsfrm(training_sgm[i], *opt_par[42+i], testing_img[7].shape)\n",
    "    sgm_img[8, i] = Trnsfrm(training_sgm[i], *opt_par[48+i], testing_img[8].shape)\n",
    "\n",
    "## Mapping each of the 2 validation segments to each of the 8 testing images    \n",
    "for i in range(2):\n",
    "    sgm_img[0, i+6] = Trnsfrm(validation_sgm[i], *opt_par_val[i]   , testing_img[0].shape)\n",
    "    sgm_img[1, i+6] = Trnsfrm(validation_sgm[i], *opt_par_val[i+2] , testing_img[1].shape)\n",
    "    sgm_img[2, i+6] =Trnsfrm(validation_sgm[i], *opt_par_val[i+4] , testing_img[2].shape)\n",
    "    sgm_img[3, i+6] =Trnsfrm(validation_sgm[i], *opt_par_val[i+6] , testing_img[3].shape)\n",
    "    sgm_img[4, i+6] =Trnsfrm(validation_sgm[i], *opt_par_val[i+8] , testing_img[4].shape)\n",
    "    sgm_img[5, i+6] =Trnsfrm(validation_sgm[i], *opt_par_val[i+10], testing_img[5].shape)\n",
    "    sgm_img[6, i+6] =Trnsfrm(validation_sgm[i], *opt_par_val[i+12], testing_img[6].shape)\n",
    "    sgm_img[7, i+6] =Trnsfrm(validation_sgm[i], *opt_par_val[i+14], testing_img[7].shape)\n",
    "    sgm_img[8, i+6] =Trnsfrm(validation_sgm[i], *opt_par_val[i+16], testing_img[8].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_set = np.zeros((9,256,256,8))\n",
    "for i in range(9):\n",
    "    for j in range(8):\n",
    "        final_set[i,:,:,j] = sgm_img[i,j,:,:,0]\n",
    "\n",
    "\n",
    "## Computing the most frequent training label        \n",
    "def Most_Freq_Label(img):\n",
    "    \n",
    "    ret = np.zeros((256,256))\n",
    "    \n",
    "    ## iterating over all the pixel values\n",
    "    for px in range(0 , len(img)):\n",
    "        for py in range(0 , len(img[0])):\n",
    "            \n",
    "            final_lbl = []\n",
    "            for i in range(len(img[0][0])):\n",
    "                final_lbl.append(img[px][py][i])\n",
    "                \n",
    "            ## storing indices of the non-zero values     \n",
    "            non_zero_val = np.nonzero(final_lbl)\n",
    "            \n",
    "            ##Finding the mode and in case of a tie picking the one which has a higher value\n",
    "            \n",
    "            final_lbl.sort()\n",
    "            cnt = Counter(final_lbl)\n",
    "            cnt_var = cnt.most_common()\n",
    "            cnt_var.sort(key = lambda x: x[1])\n",
    "            \n",
    "            mode_val = cnt_var[len(cnt_var) -1][0]\n",
    "            \n",
    "            \n",
    "            ## Ignoring mode of 0 if non zero values present in the data\n",
    "            if(len(non_zero_val[0]) > 0 and  mode_val == 0):\n",
    "                \n",
    "                temp_lbl = []\n",
    "                for i in range(0 , len(non_zero_val[0])):\n",
    "                    temp_lbl.append(final_lbl[non_zero_val[0][i]])\n",
    "                 \n",
    "                ## Finding the mode of non-zero pixel values and in case of a \n",
    "                ## tie picking the one which has a higher value\n",
    "                \n",
    "                temp_lbl.sort()\n",
    "                cnt1 = Counter(temp_lbl)\n",
    "                cnt1_var = cnt1.most_common()\n",
    "                cnt1_var.sort(key = lambda x: x[1])\n",
    "                \n",
    "                ret[px][py] = cnt1_var[len(cnt1_var) -1][0]\n",
    "            \n",
    "            ## Mapping the max of the pixel value in case obtain the same mode\n",
    "            else:\n",
    "                ret[px][py] = mode_val\n",
    "    \n",
    "    return ret        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10604aed0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Final_Most_Freq = np.zeros((9,256,256))\n",
    "\n",
    "for i in range(9):\n",
    "    Final_Most_Freq[i] = Most_Freq_Label(final_set[i])\n",
    "\n",
    "##test  \n",
    "plt.imshow(Final_Most_Freq[0], cmap = 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final Block for generating csv file\n",
    "\n",
    "b_msk_2,b_msk_3,b_msk_41,b_msk_42 = [],[],[],[]\n",
    "\n",
    "def Mask_bin(img, ROI):\n",
    "    imgb = np.array(img)\n",
    "    return (imgb == ROI)\n",
    "\n",
    "\n",
    "for i in range(9):\n",
    "    b_msk_2.append(Mask_bin(Final_Most_Freq[i], 2))\n",
    "    b_msk_42.append(Mask_bin(Final_Most_Freq[i], 42))\n",
    "    b_msk_3.append(Mask_bin(Final_Most_Freq[i], 3))\n",
    "    b_msk_41.append(Mask_bin(Final_Most_Freq[i], 41))\n",
    "    \n",
    "\n",
    "    \n",
    "## Submission to Kaggle code    \n",
    "\n",
    "brain_reg = ['-left-wm', '-left-cortex', '-right-wm', '-right-cortex']\n",
    "test_lbl = ['8','9','10','11','12','13','14','16','17']\n",
    "final_lbl = [] ##For storing the data in this format\n",
    "\n",
    "for i in test_lbl:\n",
    "    for j in brain_reg:\n",
    "        final_lbl.append(i+j)\n",
    "\n",
    "\n",
    "\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "\n",
    "data = []\n",
    "for i in range(len(test_lbl)):\n",
    "    data.append(rle_encode(b_msk_2[i]))\n",
    "    data.append(rle_encode(b_msk_3[i]))\n",
    "    data.append(rle_encode(b_msk_41[i]))\n",
    "    data.append(rle_encode(b_msk_42[i]))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "### ids: list containing the 36 IDs as described above  ###\n",
    "### data: list containing the 36 binary segmentation masks in RLE format ###\n",
    "    \n",
    "df = pd.DataFrame({\"Id\": final_lbl, \"Predicted\": data})\n",
    "df.to_csv('submission.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
